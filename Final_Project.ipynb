{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-jenkins/NBA_Champs/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZadtRodBYZZ"
      },
      "source": [
        "# import all libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from bs4 import Comment\n",
        "import requests\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEVIdizDKo7D"
      },
      "source": [
        "# list holding abbviations for all nba teams to create urls\n",
        "teams = ['ATL', 'NJN', 'BOS', 'CHA', 'CHI', \n",
        "         'CLE', 'DAL', 'DEN', 'DET', 'GSW', \n",
        "         'HOU', 'IND', 'LAC', 'LAL', 'MEM', \n",
        "         'MIA', 'MIL', 'MIN', 'NOH', 'NYK', \n",
        "         'OKC', 'ORL', 'PHI', 'PHO', 'POR', \n",
        "         'SAC', 'SAS', 'TOR', 'UTA', 'WAS']\n",
        "\n",
        "# array to hold all tables for all teams for all seasons\n",
        "every_season = []\n",
        "\n",
        "# iterate through list of all team abbreviations\n",
        "for team in teams:\n",
        "\n",
        "  # create url to scrape for team\n",
        "  url = f'https://www.basketball-reference.com/teams/{team}'\n",
        "\n",
        "  # scrape teams stats from their bball reference page\n",
        "  stats = pd.read_html(url)[0]\n",
        "\n",
        "  # select only the desired columns \n",
        "  stats = stats[[\"Team\", \"Season\", \"Rel Pace\", \"Rel ORtg\", \"Rel DRtg\", \"Playoffs\"]]\n",
        "\n",
        "  # manupulate select colums for team\n",
        "  for i in range(0,len(stats[\"Playoffs\"])):\n",
        "    # remove asterisk from team\n",
        "    stats[\"Team\"][i] = stats[\"Team\"][i].replace(\"*\", \"\")\n",
        "\n",
        "    # change playoff status to binary of if they won chip or not\n",
        "    if stats[\"Playoffs\"][i] == \"Won Finals\":\n",
        "      stats[\"Playoffs\"][i] = 1\n",
        "    else:\n",
        "      stats[\"Playoffs\"][i] = 0\n",
        "\n",
        "  # rename \"playoffs\" column to \"Chip?\"\n",
        "  stats = stats.rename(columns={\"Playoffs\":\"Chip?\"})\n",
        "  \n",
        "  # Limit to all years since the 70s\n",
        "  stats = stats.iloc[0:51, :]\n",
        "\n",
        "  # add table of teams stats to a list of tables holding all teams stats\n",
        "  every_season.append(stats)\n",
        "\n",
        "# combine all teams stats into one dataframe\n",
        "all_stats = pd.concat(every_season)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "aBcHCp_zXfsn",
        "outputId": "164df565-26f6-401d-b2b0-9b82dc0689e3"
      },
      "source": [
        "# display all teams' stats\n",
        "all_stats\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Team</th>\n",
              "      <th>Season</th>\n",
              "      <th>Rel Pace</th>\n",
              "      <th>Rel ORtg</th>\n",
              "      <th>Rel DRtg</th>\n",
              "      <th>Chip?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2020-21</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2019-20</td>\n",
              "      <td>2.7</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2018-19</td>\n",
              "      <td>3.9</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2017-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2016-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Washington Bullets</td>\n",
              "      <td>1974-75</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-6.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Capital Bullets</td>\n",
              "      <td>1973-74</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1972-73</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1971-72</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-1.4</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1970-71</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1358 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Team   Season  Rel Pace  Rel ORtg  Rel DRtg Chip?\n",
              "0        Atlanta Hawks  2020-21      -1.6       3.4       1.0     0\n",
              "1        Atlanta Hawks  2019-20       2.7      -3.4       4.2     0\n",
              "2        Atlanta Hawks  2018-19       3.9      -2.3       3.5     0\n",
              "3        Atlanta Hawks  2017-18       1.0      -3.6       2.0     0\n",
              "4        Atlanta Hawks  2016-17       1.0      -3.9      -3.1     0\n",
              "..                 ...      ...       ...       ...       ...   ...\n",
              "46  Washington Bullets  1974-75       1.6       0.3      -6.4     0\n",
              "47     Capital Bullets  1973-74      -1.5      -2.1      -3.5     0\n",
              "48   Baltimore Bullets  1972-73      -2.0      -0.5      -3.5     0\n",
              "49   Baltimore Bullets  1971-72      -1.5      -1.4      -0.3     0\n",
              "50   Baltimore Bullets  1970-71       1.4      -1.0      -1.5     0\n",
              "\n",
              "[1358 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqYMgEKGhPoH",
        "outputId": "3708b967-dc03-4fb0-c427-305ac3d8bb61"
      },
      "source": [
        "# select/adjust data to train ml model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X = all_stats.drop([\"Team\", \"Season\", \"Chip?\"], axis=1)\n",
        "y = all_stats[\"Chip?\"].values.reshape(-1, 1)\n",
        "\n",
        "# label-encode y data\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "encoded_y = label_encoder.transform(y)\n",
        "\n",
        "# One-hot encodde y data\n",
        "y = to_categorical(encoded_y)\n",
        "\n",
        "y\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J5VSugkj9f_"
      },
      "source": [
        "# split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK-HM-lgkcUS",
        "outputId": "d49a4091-4bb3-490e-c458-9f56262561a2"
      },
      "source": [
        "# train random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf = rf.fit(X_train, y_train)\n",
        "print(rf.score(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9558823529411765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MlFBMkxuyRb",
        "outputId": "a9038d2d-6707-46e1-c556-7755b96205d9"
      },
      "source": [
        "# weighted importance of each stat towards winning a basketball game\n",
        "sorted(zip(bf.feature_importances_, X.columns), reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.45078943560245877, 'Rel ORtg'),\n",
              " (0.4172580486702902, 'Rel DRtg'),\n",
              " (0.13195251572725109, 'Rel Pace')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "V5vNSBmnBNPq",
        "outputId": "bb4a7af0-664c-425c-f83c-3d80dfbbd595"
      },
      "source": [
        "# create array to hold binary model predictions\n",
        "predictions = []\n",
        "\n",
        "# convert hot encoded preditions back to binary values\n",
        "for pred in rf.predict(X):\n",
        "  if pred[1] == 0.:\n",
        "    predictions.append(0)\n",
        "  else:\n",
        "    predictions.append(1)\n",
        "\n",
        "# create new dataframe to hold stats with predictions\n",
        "champs = all_stats\n",
        "champs[\"Predicted\"] = predictions\n",
        "\n",
        "# show dataframe with all stats and championship predictions\n",
        "champs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Team</th>\n",
              "      <th>Season</th>\n",
              "      <th>Rel Pace</th>\n",
              "      <th>Rel ORtg</th>\n",
              "      <th>Rel DRtg</th>\n",
              "      <th>Chip?</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2020-21</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2019-20</td>\n",
              "      <td>2.7</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2018-19</td>\n",
              "      <td>3.9</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2017-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>2016-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Washington Bullets</td>\n",
              "      <td>1974-75</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-6.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Capital Bullets</td>\n",
              "      <td>1973-74</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1972-73</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1971-72</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-1.4</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Baltimore Bullets</td>\n",
              "      <td>1970-71</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1358 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Team   Season  Rel Pace  Rel ORtg  Rel DRtg Chip?  Predicted\n",
              "0        Atlanta Hawks  2020-21      -1.6       3.4       1.0     0          0\n",
              "1        Atlanta Hawks  2019-20       2.7      -3.4       4.2     0          0\n",
              "2        Atlanta Hawks  2018-19       3.9      -2.3       3.5     0          0\n",
              "3        Atlanta Hawks  2017-18       1.0      -3.6       2.0     0          0\n",
              "4        Atlanta Hawks  2016-17       1.0      -3.9      -3.1     0          0\n",
              "..                 ...      ...       ...       ...       ...   ...        ...\n",
              "46  Washington Bullets  1974-75       1.6       0.3      -6.4     0          0\n",
              "47     Capital Bullets  1973-74      -1.5      -2.1      -3.5     0          0\n",
              "48   Baltimore Bullets  1972-73      -2.0      -0.5      -3.5     0          0\n",
              "49   Baltimore Bullets  1971-72      -1.5      -1.4      -0.3     0          0\n",
              "50   Baltimore Bullets  1970-71       1.4      -1.0      -1.5     0          0\n",
              "\n",
              "[1358 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAwQm3mSE3Lt",
        "outputId": "035c4726-ec89-4e2c-f965-90f0eeac52e1"
      },
      "source": [
        "# create lists to hold overachieving and disappointing teams\n",
        "overachievers = []\n",
        "disappointments = []\n",
        "\n",
        "# iterate through all seasons for all teams\n",
        "for i in range(0, len(champs[\"Season\"])):\n",
        "\n",
        "  # if model said a team wouldnt win the chip but they do then add them to overachievers\n",
        "  if (champs[\"Chip?\"].values[i] == 1) and (champs[\"Predicted\"].values[i] == 0):\n",
        "    overachievers.append(f'{champs[\"Season\"].values[i]} {champs[\"Team\"].values[i]}')\n",
        "\n",
        "  # if model said a team would win the chip but the don't then add them to disappointments\n",
        "  elif (champs[\"Chip?\"].values[i] == 0) and (champs[\"Predicted\"].values[i] == 1):\n",
        "    disappointments.append(f'{champs[\"Season\"].values[i]} {champs[\"Team\"].values[i]}')\n",
        "\n",
        "# show both lists\n",
        "print(overachievers)\n",
        "print(disappointments)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1975-76 New York Nets', '2007-08 Boston Celtics', '1975-76 Boston Celtics', '2015-16 Cleveland Cavaliers', '2010-11 Dallas Mavericks', '1988-89 Detroit Pistons', '2016-17 Golden State Warriors', '1987-88 Los Angeles Lakers', '1972-73 New York Knicks', '1978-79 Seattle SuperSonics', '2004-05 San Antonio Spurs', '1998-99 San Antonio Spurs', '2018-19 Toronto Raptors', '1977-78 Washington Bullets']\n",
            "['1971-72 Milwaukee Bucks']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcItg16YHyO8",
        "outputId": "5f9fe979-a382-4aaf-c8ef-c9eb0e3e178b"
      },
      "source": [
        "type(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQciv577mka_"
      },
      "source": [
        "# # tune hyperparameters\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # create new model whose hyperparamaters are to be tuned\n",
        "# forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# # store some tuning options in a dictionary\n",
        "# hyper = {'n_estimators': [10, 25, 50, 100, 200], \n",
        "#          'max_depth': [3, 5, 8, 15]}\n",
        "\n",
        "# # create GridSearch model\n",
        "# grid = GridSearchCV(forest, hyper, cv = 3, verbose = 1, n_jobs = -1)\n",
        "\n",
        "# # Train the model with GridSearch\n",
        "# fitted = grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # display best parameters and the score they get\n",
        "# print(fitted.best_params_)\n",
        "# print(fitted.best_score_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxvedOfod18"
      },
      "source": [
        "# best_forest = RandomForestClassifier(max_depth=3, n_estimators=10, random_state=42)\n",
        "# bf = best_forest.fit(X_train_scaled, y_train)\n",
        "# # **(why is score different than the \"fitted\" score in the cell above)\n",
        "# print(bf.score(X_test_scaled, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWmBs3EkSdx4"
      },
      "source": [
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#from matplotlib import style\n",
        "#style.use(\"ggplot\")\n",
        "#from matplotlib import rcParams\n",
        "#rcParams['figure.figsize'] = 10, 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D26QwXFYszm"
      },
      "source": [
        "#df = pd.dataFrame(os.path.join(\"..\", \"Chip?\", \"Season\", \"Team\"))\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6sUv-_NSdAa"
      },
      "source": [
        "#target = df[\"Chip?\"]\n",
        "#target_names = [\"Season\", \"team\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yEz4yy3UqTt"
      },
      "source": [
        "#data = df.drop(\"Chip?\", axis=1)\n",
        "#feature_names = data.columns\n",
        "#data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88JVGB6xVYyk"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WP0gT_NVoUi"
      },
      "source": [
        "#from sklearn.svm import SVC \n",
        "#model = SVC(kernel='linear')\n",
        "#model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92zhEGxGXY4P"
      },
      "source": [
        "#print('Test Acc: %.3f' % model.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GehObSUbDvo"
      },
      "source": [
        "#from sklearn.metrics import classification_report\n",
        "#predictions = model.predict(X_test)\n",
        "#print(classification_report(y_test, predictions,\n",
        "                            #target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S8MW4oy8aB7"
      },
      "source": [
        "**ETL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYVd81e5KQdZ",
        "outputId": "066a130f-1ed5-4fff-831c-9291bacd4098"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.1.1'\n",
        "\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (114 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdBT2MFBKbYF"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NbaChamps\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0mRBziwiu_",
        "outputId": "3dc2ac94-8527-4dc1-b12b-85295e82b885"
      },
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-09 03:29:16--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: â€˜postgresql-42.2.9.jar.4â€™\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  4.36MB/s    in 0.2s    \n",
            "\n",
            "2021-06-09 03:29:17 (4.36 MB/s) - â€˜postgresql-42.2.9.jar.4â€™ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV5lwm7Rkdyl",
        "outputId": "29828681-25c3-4aa4-9b54-8b6ed79150ec"
      },
      "source": [
        "all_stats.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Team          object\n",
              "Season        object\n",
              "Rel Pace     float64\n",
              "Rel ORtg     float64\n",
              "Rel DRtg     float64\n",
              "Chip?         object\n",
              "Predicted      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLKSnNxkug9V",
        "outputId": "85f08601-9244-4f76-87bf-6aa20855000b"
      },
      "source": [
        "# Rename Columns for postgres consumption\n",
        "all_stats_copy = all_stats.copy()\n",
        "all_stats_py = all_stats_copy.rename(columns={\"Rel Pace\": \"Rel_Pace\", \"Rel ORtg\": \"Rel_ORtg\", \"Rel DRtg\": \"Rel_DRtg\", \"Chip?\": \"Chip\"})\n",
        "\n",
        "# Convert Pandas df to Pyspark df\n",
        "all_stats_py = spark.createDataFrame(all_stats_py)\n",
        "all_stats_py.printSchema()\n",
        "# all_stats_py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Team: string (nullable = true)\n",
            " |-- Season: string (nullable = true)\n",
            " |-- Rel_Pace: double (nullable = true)\n",
            " |-- Rel_ORtg: double (nullable = true)\n",
            " |-- Rel_DRtg: double (nullable = true)\n",
            " |-- Chip: long (nullable = true)\n",
            " |-- Predicted: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KersOHcuhiK"
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://nba-champs.c6ka6apltccn.us-east-2.rds.amazonaws.com:5432/nbachamps\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\": \"MildredChase84!\",\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E2Tn3IAtuhys",
        "outputId": "a96a6dd2-254c-4e85-df85-0d5ccf48ca3b"
      },
      "source": [
        "# Write DataFrame to Nba champs table in RDS\n",
        "\n",
        "all_stats_py.write.jdbc(url=jdbc_url, table='all_stats', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-1a9829e0627d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write DataFrame to Nba champs table in RDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_stats_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all_stats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o227.jdbc.\n: java.lang.ClassNotFoundException: org.postgresql.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:471)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:102)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:102)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:102)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:215)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:219)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:45)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:817)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a0371kVuh4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}